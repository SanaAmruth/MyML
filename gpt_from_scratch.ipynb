{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step by step process**\n",
    "- x_train y_train extraction\n",
    "- get_batch function\n",
    "- gpt class declaration\n",
    "    - layers present\n",
    "        - embedding (vocab,embed)\n",
    "        - positional embedding (vocab,embed)\n",
    "        - add them to get x\n",
    "        - Multi-headed attention(n_heads, head_dim = embed_dim)\n",
    "            - each_head\n",
    "                - key(embed, head_size/n_heads), query(embed, head_size/n_heads), value(embed, head_size/n_heads) # (B,T,head_size/n_head)\n",
    "            - concat in last dimension # (B,T,head_size)\n",
    "            - linear layer(head_size, vocab_size)\n",
    "    - forward pass\n",
    "    - generate/inference\n",
    "    - training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fac0bce7bb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text extraction\n",
    "with open('/Users/sana/Desktop/tmp/input.txt', 'r') as file:\n",
    "    contents = file.read()\n",
    "len(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split in text\n",
    "train_text, test_text = contents[:int(0.8*len(contents))],contents[int(0.8*len(contents)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary extraction\n",
    "vocab = sorted((set(list(contents))))\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation unit functions\n",
    "stoi = {i:idx for idx,i in enumerate(vocab)}\n",
    "atoi = {idx:i for idx,i in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual tokenisation\n",
    "tokenize = lambda s: [stoi[i] for i in s]\n",
    "# tokenize = lambda s: list(map(stoi,s))\n",
    "de_tokenize = lambda list_of_tokens: \"\".join([atoi[i] for i in list_of_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[57, 39, 52, 39]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit testing for tokenization\n",
    "tokenize(\"sana\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sana'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit testing for de-tokenization\n",
    "de_tokenize([57, 39, 52, 39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "lr = 1e-3\n",
    "context_len = 8\n",
    "batch_size = 4 \n",
    "embed_dim = 64\n",
    "n_batches_to_estimate_loss = 200\n",
    "n_heads = 4\n",
    "n_blocks = 6\n",
    "dropout = 0.2\n",
    "# n_embed = head_dim//n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text_train and text_test in tokens\n",
    "train_tokens = tokenize(train_text)\n",
    "test_tokens = tokenize(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = ['train','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting one batch from given text\n",
    "def get_batch(split, context_len = context_len, batch_size = batch_size):\n",
    "    list_tokens = train_tokens if split == 'train' else test_tokens\n",
    "    idx = torch.randint(0,len(list_tokens)-context_len-1,(batch_size,))\n",
    "    x = torch.stack([torch.tensor(list_tokens[i:i+context_len]) for i in idx])\n",
    "    y = torch.stack([torch.tensor(list_tokens[i+1:i+context_len+1]) for i in idx])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit testing for get_batch\n",
    "x, y = get_batch('test', 8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(any_list):\n",
    "    return sum(any_list)/len(any_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class head(nn.Module):\n",
    "    def __init__(self, head_dim):\n",
    "        super().__init__()\n",
    "        # print(f\"embed_dim={embed_dim},head_dim={head_dim}\")\n",
    "        # embed_dim = head_dim\n",
    "        # head_dim = head_dim\n",
    "        self.key = nn.Linear(embed_dim,head_dim)\n",
    "        self.value = nn.Linear(embed_dim,head_dim)\n",
    "        self.query = nn.Linear(embed_dim,head_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x --> (B,T,embed_dim)\n",
    "        T = x.shape[-2]\n",
    "        key = self.key(x)       # (B,T,head_len)\n",
    "        query = self.query(x)   # (B,T,head_len)\n",
    "        value = self.value(x)   # (B,T,head_len)\n",
    "        attention_weights = query @ key.transpose(-2, -1) * T**(-0.5) # (B,T,T)\n",
    "        tril = torch.tril(torch.ones((T,T)))  # (T,T)\n",
    "        causal_attention_weights = attention_weights.masked_fill(tril==0, float('-inf')) # (B,T,T)\n",
    "        causal_attention_weights = F.softmax(causal_attention_weights, dim = -1) \n",
    "        causal_attention_weights = self.dropout(causal_attention_weights)\n",
    "        new_values = causal_attention_weights @ value   # (B,T,head_len)\n",
    "        # new_values = F.softmax(new_values, dim = -1)    # (B,T,head_len)\n",
    "        return new_values   # (B,T,head_len)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_headed_attention(nn.Module):\n",
    "    def __init__(self, n_head, embed_dim):\n",
    "        super().__init__()\n",
    "        each_head_dim = embed_dim//n_head\n",
    "        self.heads = nn.ModuleList([head(each_head_dim)for _ in range(n_head)])\n",
    "        self.proj = nn.Linear(n_head*each_head_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        # x --> (B,T, embed_dim)\n",
    "        # print(self.multi_head[0](x).shape)\n",
    "        out = torch.cat([single_head(x) for single_head in self.heads],dim=-1) # each_head(x) --> (B,T,head_dim/n_heads)\n",
    "        # print(f\"out.shape ->{out.shape}\")\n",
    "        out = self.dropout(self.proj(out)) #(B,T,embed_dim)\n",
    "        # print(f\"out.shape --> {out.shape}\")\n",
    "        # multi_head_attended_vectors --> (B,T,head_dim)\n",
    "        return out  # (B,T,embed_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward_NN(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.ff_net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4*n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embed, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        y = self.ff_net(x) #(B, T, head_dim)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_head, embed_dim):\n",
    "        super().__init__()\n",
    "        # head_size = embed_dim//n_head\n",
    "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.multi_head = Multi_headed_attention(n_head, embed_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = FeedForward_NN(embed_dim)\n",
    "    def forward(self,x):\n",
    "        # print(f\"x->bef shape{x.shape}\")\n",
    "        # print(\"a = {a}\")\n",
    "        # a = a + 1\n",
    "        # print(x.shape)\n",
    "        x = x + self.multi_head(self.layer_norm1(x)) #(B,T,embed_dim)\n",
    "        # print(f\"x->aft shape{x.shape}\")\n",
    "        x = x + self.ffn(self.layer_norm2(x)) #(B,T,n_embed)\n",
    "        return x\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_gpt(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, context_length):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(context_length,embed_dim)\n",
    "        self.blocks = nn.Sequential(*[Block(n_heads,embed_dim) for _ in range(n_blocks)])\n",
    "        # self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "        self.ln_f = nn.LayerNorm(embed_dim) # final layer norm\n",
    "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    def forward(self, x, targets=None):\n",
    "        # x --> (B,T)\n",
    "        B,T = x.shape\n",
    "        # x = x[:,-T:,:]s\n",
    "        token_to_embedding = self.embedding(x) #(B,T,embed_dim)\n",
    "        # print(f\"token_to_embedding : {token_to_embedding.shape}\")\n",
    "        positional_embeddings = self.positional_embedding(torch.tensor([i for i in range(T)])) # (T,embed_dim)\n",
    "        # print(f\"positional_embedding : {positional_embeddings.shape}\")\n",
    "        combined_embeddings = token_to_embedding + positional_embeddings # (B,T,embed_dim)\n",
    "        # attention_vectors = self.head(combined_embeddings) # (B,T,head_len)\n",
    "        # print(f\"combined embeddings shape : {combined_embeddings.shape}\")\n",
    "        # print(f\"n_heads = {n_heads}, head_dim = {head_dim}\")\n",
    "        # multi_headed_attention_vectors = self.mutli_head(combined_embeddings) #(B,T,head_dim)\n",
    "        out = self.blocks(combined_embeddings)\n",
    "        # print(f\"out shape : {out.shape}\")\n",
    "        out = self.ln_f(out)\n",
    "        logits = self.lm_head(out)\n",
    "        # logits = self.linear(multi_headed_attention_vectors) # (B,T,vocab_size)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, vocab_size = logits.shape\n",
    "            logits = logits.view(B*T, vocab_size) #(B*T,vocab_size)\n",
    "            targets = targets.view(B*T) # (B*T,)\n",
    "            loss = F.cross_entropy(logits, targets)  # loss --> constant\n",
    "        return logits,loss\n",
    "        # pass\n",
    "    \n",
    "    def train(self, x_train_tokens, n_iterations):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = 1e-3)\n",
    "        # store losses in all iterations to observe the convergence of training\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for iter in tqdm(range(n_iterations)):\n",
    "            # x --> (B,T)    targets --> (B,T)\n",
    "            if iter%500 == 0:\n",
    "                t,v = self.estimate_loss(n_batches_to_estimate_loss = n_batches_to_estimate_loss)\n",
    "                train_losses.append(t)\n",
    "                val_losses.append(v)\n",
    "            x_train, y_train = get_batch(x_train_tokens, context_len = 8, batch_size = 4)\n",
    "            _, loss = self(x_train,y_train)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # losses.append(loss.item())\n",
    "        # plt.plot([i for i in range(len(train_losses))],train_losses)\n",
    "        plt.plot([i for i in range(len(val_losses))],val_losses)\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Validation loss\")\n",
    "    \n",
    "    @torch.no_grad\n",
    "    def estimate_loss(self, n_batches_to_estimate_loss):\n",
    "        losses = dict()\n",
    "        for split in ['train','test']:\n",
    "            total_loss = []\n",
    "            for _ in range(n_batches_to_estimate_loss):\n",
    "                x, y = get_batch(split,context_len = context_len, batch_size = batch_size)\n",
    "                _, loss = self(x, y)\n",
    "                total_loss.append(loss.item())\n",
    "            losses[split] = mean(total_loss)\n",
    "        return losses['train'], losses['test']\n",
    "\n",
    "    @torch.no_grad\n",
    "    def generate(self,x,num_max_tokens):\n",
    "        # x --> (B,T)\n",
    "        T = x.shape[-1]\n",
    "        for _ in range(num_max_tokens):\n",
    "            inputs = x[:,-T:] # (B,T)\n",
    "            logits,_ = self(inputs) # (B,T,vocab_size)\n",
    "            logits = logits[:,-1,:] # (B,vocab_size)\n",
    "            # print(logits.shape)\n",
    "            probs = F.softmax(logits,dim = -1)  # (B,vocab_size)\n",
    "            # print(probs.shape)\n",
    "            pred = torch.multinomial(probs, num_samples = 1)    #( B)\n",
    "            # print(pred.shape)\n",
    "            # print(x.shape)\n",
    "            x = torch.cat((x,pred),dim = 1)\n",
    "            # print(x.shape)\n",
    "            # return x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_gpt(embed_dim, vocab_size = vocab_size, context_length = context_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_gpt(\n",
      "  (embedding): Embedding(65, 64)\n",
      "  (positional_embedding): Embedding(8, 64)\n",
      "  (blocks): Sequential(\n",
      "    (0): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Block(\n",
      "      (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (multi_head): Multi_headed_attention(\n",
      "        (heads): ModuleList(\n",
      "          (0-3): 4 x head(\n",
      "            (key): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (value): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (query): Linear(in_features=64, out_features=16, bias=True)\n",
      "            (dropout): Dropout(p=0.2, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): FeedForward_NN(\n",
      "        (ff_net): Sequential(\n",
      "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): Linear(in_features=64, out_features=65, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 65])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d will nr;QgnfaXhcOSud FVIYobz&!iFRLoapcUD mT:Sz&R:NpC$&\\nW&UICQR:zUl ,cfbODGhPryv\\nbVKpjw-IOmuBKIMX!ZbwGrwz.j',\n",
       " \"HIO:\\nNowoPrDrUvZzarfHNY'ZqxAxtPh&'U'r:U,fM,MljCAp3d\\n:\\n&AvR&,&WQwPVrcnMIM&xEPNkVkSDqppogK.gBEDTBksJ.o-whl'?Mx\",\n",
       " 'truth apX?unO3,hhwc Tgql:xKVFDIhrUGLlnvqIEMCSp IJiIXiYUo3MxZYmFvVdGrV$E sJXfXvZ!gfYJEcj.kR?mKRlHfnuX3A;!jzzP',\n",
       " 'with\\ncon;ATqUPDgz-zqCdmDQCDII:uTepH&Qz-YPn:FXJEGTQleAHGbdzULw;GsWAwd dpvUA?Pm!O3mEZp3k Wz-Ohc.sbvQzmGh.QvApQ']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check inference of the model before training to generate new_tokens for uncompleted strings\n",
    "generated_tokens = model.generate(x,100)\n",
    "generated_strings = [de_tokenize(generated_tokens[i,:].tolist()) for i in range(4)]\n",
    "generated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 16.96it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train_tokens,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d will na teo, s h',\n",
       " 'HIO:\\nNow vib sodal',\n",
       " 'truth ap auad,ed\\nU',\n",
       " 'with\\ncon,\\nI\\n.K\\n: n']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_tokens = model.generate(x,10)\n",
    "generated_strings = [de_tokenize(generated_tokens[i,:].tolist()) for i in range(batch_size)]\n",
    "generated_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"d will now or a osteme jase; duch Gowreice ratind efour us; bLUsikn duily wer taninsear hapir.\\n\\nPROUDIO:\\nTo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "a\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "a = \"a\\nt\"\n",
    "print(len(a))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "\n",
      "\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
